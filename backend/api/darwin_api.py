import os
import json
import threading
import time
import logging
from datetime import datetime, date, timezone, timedelta
from typing import Dict, Tuple, Optional, List, Any
from pathlib import Path
import sqlite3
from dataclasses import dataclass, asdict

from confluent_kafka import Consumer
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

"""
Realtime Darwin (JSON topic) -> train position estimator + HTTP API
- Consumes Kafka JSON (RDM Darwin Push Port JSON topic)
- Normalizes payload (wrapper with/without `bytes`; Location list/object)
- Estimates realtime position via time interpolation between TIPLOCs
- Exposes /positions & debug endpoints for quick inspection

Run:
  pip install confluent_kafka fastapi uvicorn pydantic
  export KAFKA_USERNAME=...
  export KAFKA_PASSWORD=...
  export KAFKA_GROUP=SC-062cd84d-9e2f-41ae-a702-d3f9c1a72cc3
  uvicorn darwin_realtime_consumer:app --host 0.0.0.0 --port 8000
"""

# ===== Configuration ===== #
@dataclass
class Config:
    # Kafkaé…ç½®
    bootstrap: str = os.getenv("KAFKA_BOOTSTRAP", "pkc-z3p1v0.europe-west2.gcp.confluent.cloud:9092")
    topic: str = os.getenv("KAFKA_TOPIC", "prod-1010-Darwin-Train-Information-Push-Port-IIII2_0-JSON")
    username: str = os.getenv("KAFKA_USERNAME", "")
    password: str = os.getenv("KAFKA_PASSWORD", "")
    group_id: str = os.getenv("KAFKA_GROUP", "SC-062cd84d-9e2f-41ae-a702-d3f9c1a72cc3")
    auto_reset: str = os.getenv("KAFKA_AUTO_OFFSET", "earliest")
    
    # æ›´æ–°é…ç½®
    update_interval: int = int(os.getenv("UPDATE_INTERVAL", "300"))  # 5åˆ†é’Ÿé»˜è®¤
    max_age_hours: int = int(os.getenv("MAX_AGE_HOURS", "24"))  # 24å°æ—¶åæ¸…ç†æ—§æ•°æ®
    
    # æ•°æ®åº“é…ç½®
    db_path: str = os.getenv("DB_PATH", "data/database/train_positions.db")
    
    # æ—¥å¿—é…ç½®
    log_level: str = os.getenv("LOG_LEVEL", "INFO")

config = Config()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, config.log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ===== æ•°æ®åº“ç®¡ç† ===== #
class DatabaseManager:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.init_db()
    
    def init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS train_positions (
                    rid TEXT PRIMARY KEY,
                    uid TEXT,
                    ts TEXT,
                    from_tpl TEXT,
                    to_tpl TEXT,
                    lat REAL,
                    lon REAL,
                    ratio REAL,
                    state TEXT,
                    platform TEXT,
                    updated_at TEXT,
                    raw_data TEXT
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS tiploc_coords (
                    tiploc TEXT PRIMARY KEY,
                    lat REAL,
                    lon REAL,
                    name TEXT,
                    source TEXT,
                    updated_at TEXT
                )
            """)
            
            # æ’å…¥ä¸€äº›åŸºç¡€TIPLOCåæ ‡
            self.load_default_tiplocs()
    
    def load_default_tiplocs(self):
        """åŠ è½½é»˜è®¤çš„TIPLOCåæ ‡"""
        default_tiplocs = [
            ("CRLN", 51.4863, 0.0361, "Charlton", "manual"),
            ("WOLWCDY", 51.4909, 0.0540, "Woolwich Dockyard", "manual"),
            ("WOLWCHA", 51.4916, 0.0694, "Woolwich Arsenal", "manual"),
            ("TUTBURY", 52.8730, -1.6870, "Tutbury & Hatton", "manual"),
            ("LONDON", 51.5074, -0.1278, "London", "manual"),
            ("BRMNGM", 52.4862, -1.8904, "Birmingham", "manual"),
            ("MNCHSTR", 53.4808, -2.2426, "Manchester", "manual"),
            ("EDINBGH", 55.9533, -3.1883, "Edinburgh", "manual"),
        ]
        
        with sqlite3.connect(self.db_path) as conn:
            for tiploc, lat, lon, name, source in default_tiplocs:
                conn.execute("""
                    INSERT OR IGNORE INTO tiploc_coords 
                    (tiploc, lat, lon, name, source, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (tiploc, lat, lon, name, source, datetime.now().isoformat()))
    
    def get_tiploc_coords(self, tiploc: str) -> Optional[Tuple[float, float]]:
        """è·å–TIPLOCåæ ‡"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT lat, lon FROM tiploc_coords WHERE tiploc = ?", 
                (tiploc,)
            )
            result = cursor.fetchone()
            return (result[0], result[1]) if result else None
    
    def save_position(self, position_data: dict):
        """ä¿å­˜ä½ç½®æ•°æ®åˆ°æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO train_positions 
                (rid, uid, ts, from_tpl, to_tpl, lat, lon, ratio, state, platform, updated_at, raw_data)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                position_data.get("rid"),
                position_data.get("uid"),
                position_data.get("ts"),
                position_data.get("from_tpl"),
                position_data.get("to_tpl"),
                position_data.get("lat"),
                position_data.get("lon"),
                position_data.get("ratio"),
                position_data.get("state"),
                position_data.get("platform"),
                datetime.now().isoformat(),
                json.dumps(position_data)
            ))
    
    def get_all_positions(self, max_age_hours: int = 24) -> List[dict]:
        """è·å–æ‰€æœ‰ä½ç½®æ•°æ®"""
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT rid, uid, ts, from_tpl, to_tpl, lat, lon, ratio, state, platform, updated_at
                FROM train_positions 
                WHERE updated_at > ?
                ORDER BY updated_at DESC
            """, (cutoff_time.isoformat(),))
            
            columns = [desc[0] for desc in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
    
    def cleanup_old_data(self, max_age_hours: int = 24):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "DELETE FROM train_positions WHERE updated_at < ?",
                (cutoff_time.isoformat(),)
            )
            deleted_count = cursor.rowcount
            logger.info(f"æ¸…ç†äº† {deleted_count} æ¡æ—§çš„ä½ç½®è®°å½•")

# åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
db_manager = DatabaseManager(config.db_path)

# ===== çŠ¶æ€ç®¡ç† ===== #
class StateManager:
    def __init__(self):
        self.latest: Dict[str, dict] = {}  # rid -> latest position snapshot
        self.last_wrapper: Optional[dict] = None
        self.last_payload: Optional[dict] = None
        self.last_error: Optional[str] = None
        self.message_count: int = 0
        self.error_count: int = 0
        self.last_update: Optional[datetime] = None
        self.consumer_active: bool = False
        
    def update_position(self, rid: str, position_data: dict):
        """æ›´æ–°ä½ç½®æ•°æ®"""
        self.latest[rid] = position_data
        self.last_update = datetime.now()
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        try:
            db_manager.save_position(position_data)
        except Exception as e:
            logger.error(f"ä¿å­˜ä½ç½®æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    def get_all_positions(self) -> List[dict]:
        """è·å–æ‰€æœ‰ä½ç½®æ•°æ®ï¼ˆå†…å­˜+æ•°æ®åº“ï¼‰"""
        # åˆå¹¶å†…å­˜ä¸­çš„æ•°æ®å’Œæ•°æ®åº“ä¸­çš„æ•°æ®
        memory_positions = list(self.latest.values())
        db_positions = db_manager.get_all_positions(config.max_age_hours)
        
        # ä½¿ç”¨ridå»é‡ï¼Œä¼˜å…ˆä½¿ç”¨å†…å­˜ä¸­çš„æ•°æ®
        positions_dict = {}
        
        # å…ˆæ·»åŠ æ•°æ®åº“ä¸­çš„æ•°æ®
        for pos in db_positions:
            positions_dict[pos['rid']] = pos
        
        # å†æ·»åŠ å†…å­˜ä¸­çš„æ•°æ®ï¼ˆä¼šè¦†ç›–æ•°æ®åº“ä¸­çš„æ—§æ•°æ®ï¼‰
        for pos in memory_positions:
            positions_dict[pos['rid']] = pos
        
        return list(positions_dict.values())
    
    def cleanup_old_positions(self):
        """æ¸…ç†æ—§çš„ä½ç½®æ•°æ®"""
        cutoff_time = datetime.now() - timedelta(hours=config.max_age_hours)
        
        # æ¸…ç†å†…å­˜ä¸­çš„æ—§æ•°æ®
        old_rids = []
        for rid, pos in self.latest.items():
            try:
                pos_time = datetime.fromisoformat(pos.get('ts', ''))
                if pos_time < cutoff_time:
                    old_rids.append(rid)
            except:
                # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä¹Ÿæ¸…ç†æ‰
                old_rids.append(rid)
        
        for rid in old_rids:
            del self.latest[rid]
        
        if old_rids:
            logger.info(f"ä»å†…å­˜ä¸­æ¸…ç†äº† {len(old_rids)} æ¡æ—§çš„ä½ç½®è®°å½•")
        
        # æ¸…ç†æ•°æ®åº“ä¸­çš„æ—§æ•°æ®
        db_manager.cleanup_old_data(config.max_age_hours)

state_manager = StateManager()

# ===== Helpers ===== #

def coord_of(tpl: str) -> Optional[Tuple[float, float]]:
    """è·å–TIPLOCåæ ‡"""
    return db_manager.get_tiploc_coords(tpl)


def parse_time_hms_local(s: str, ssd: str, tzinfo: Optional[timezone]) -> datetime:
    """Convert "HH:MM" or "HH:MM:SS" + service date (ssd) -> timezone-aware datetime."""
    if not s:
        raise ValueError("empty time string")
    fmt = "%H:%M" if len(s) == 5 else "%H:%M:%S"
    t = datetime.strptime(s, fmt).time()
    base = datetime.fromisoformat(ssd).date() if ssd else date.today()
    return datetime.combine(base, t, tzinfo=tzinfo)


def pick_time(loc: dict, key: str, ssd: str, tzinfo: Optional[timezone]) -> Optional[datetime]:
    """Priority: actual (at/atd) > expected (et) > public timetable (pt[a|d]) > working timetable (wt[a|d|p])."""
    node = loc.get(key)
    if isinstance(node, dict):
        for cand in ("at", "et"):
            v = node.get(cand)
            if v:
                return parse_time_hms_local(v, ssd, tzinfo)
    # fallback to planned
    for cand in (f"pt{key[-1]}", f"wt{key[-1]}", "wtp"):
        v = loc.get(cand)
        if v:
            return parse_time_hms_local(v, ssd, tzinfo)
    return None


def find_prev_next(locations: List[dict], ssd: str, now: datetime) -> Optional[Tuple[dict, dict, datetime, datetime]]:
    """Find last departed (prev) and next arriving/passing (next), with their times (tzâ€‘aware)."""
    prev = None
    for i, loc in enumerate(locations):
        dep = pick_time(loc, "dep", ssd, now.tzinfo)
        arr = pick_time(loc, "arr", ssd, now.tzinfo)
        pas = loc.get("pass") if isinstance(loc.get("pass"), dict) else None
        pas_t = None
        if pas:
            x = pas.get("at") or pas.get("et")
            if x:
                pas_t = parse_time_hms_local(x, ssd, now.tzinfo)
        left_time = dep or pas_t or arr
        if left_time and left_time <= now:
            prev = (i, loc, left_time)
        if prev and i > prev[0]:
            next_time = pick_time(loc, "arr", ssd, now.tzinfo)
            if not next_time and pas and pas.get("et"):
                next_time = parse_time_hms_local(pas["et"], ssd, now.tzinfo)
            if next_time and next_time >= now:
                return prev[1], loc, prev[2], next_time
    return None


def lerp(a: float, b: float, t: float) -> float:
    t = 0.0 if t < 0 else 1.0 if t > 1 else t
    return a + (b - a) * t


def estimate_position(prev_loc: dict, next_loc: dict, t0: datetime, t1: datetime, now: datetime) -> Optional[dict]:
    p = coord_of(prev_loc.get("tpl"))
    n = coord_of(next_loc.get("tpl"))
    if not p or not n:
        return None
    total = (t1 - t0).total_seconds()
    ratio = 1.0 if total <= 0 else (now - t0).total_seconds() / total
    lat = lerp(p[0], n[0], ratio)
    lon = lerp(p[1], n[1], ratio)
    state = "enroute"
    # Dwell if arrived at next but not yet departed
    dep_next = pick_time(next_loc, "dep", t1.date().isoformat(), now.tzinfo)
    arr_next = pick_time(next_loc, "arr", t1.date().isoformat(), now.tzinfo)
    if arr_next and arr_next <= now and (not dep_next or dep_next > now):
        lat, lon, state = n[0], n[1], "dwell"
    return {"lat": lat, "lon": lon, "ratio": max(0.0, min(1.0, ratio)), "state": state}


# ===== Kafkaæ¶ˆè´¹è€…ç®¡ç† ===== #
class KafkaConsumerManager:
    def __init__(self):
        self.consumer = None
        self.running = False
        self.thread = None
        
    def create_consumer(self):
        """åˆ›å»ºKafkaæ¶ˆè´¹è€…"""
        if not config.username or not config.password:
            logger.warning("Kafkaç”¨æˆ·åæˆ–å¯†ç æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return None
            
        return Consumer({
            "bootstrap.servers": config.bootstrap,
            "security.protocol": "SASL_SSL",
            "sasl.mechanism": "PLAIN",
            "sasl.username": config.username,
            "sasl.password": config.password,
            "group.id": config.group_id,
            "auto.offset.reset": config.auto_reset,
            # å¥å£®æ€§é…ç½®
            "client.dns.lookup": "use_all_dns_ips",
            "broker.address.family": "v4",
            "socket.keepalive.enable": True,
            "session.timeout.ms": 30000,
            "heartbeat.interval.ms": 10000,
        })
    
    def start(self):
        """å¯åŠ¨æ¶ˆè´¹è€…"""
        if self.running:
            return
            
        self.consumer = self.create_consumer()
        if self.consumer:
            self.consumer.subscribe([config.topic])
            self.running = True
            self.thread = threading.Thread(target=self.consume_loop, daemon=True)
            self.thread.start()
            logger.info("Kafkaæ¶ˆè´¹è€…å·²å¯åŠ¨")
        else:
            # å¯åŠ¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨
            self.running = True
            self.thread = threading.Thread(target=self.mock_data_loop, daemon=True)
            self.thread.start()
            logger.info("æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…"""
        self.running = False
        if self.consumer:
            self.consumer.close()
        logger.info("Kafkaæ¶ˆè´¹è€…å·²åœæ­¢")
    
    def consume_loop(self):
        """æ¶ˆè´¹å¾ªç¯"""
        state_manager.consumer_active = True
        last_cleanup = datetime.now()
        
        while self.running:
            try:
                msg = self.consumer.poll(1.0)
                if msg is None:
                    continue
                    
                if msg.error():
                    state_manager.last_error = str(msg.error())
                    state_manager.error_count += 1
                    logger.error(f"Kafkaé”™è¯¯: {msg.error()}")
                    continue
                
                self.process_message(msg)
                
                # å®šæœŸæ¸…ç†æ—§æ•°æ®
                if datetime.now() - last_cleanup > timedelta(hours=1):
                    state_manager.cleanup_old_positions()
                    last_cleanup = datetime.now()
                    
            except Exception as e:
                state_manager.last_error = str(e)
                state_manager.error_count += 1
                logger.error(f"æ¶ˆè´¹æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
                time.sleep(5)  # å‡ºé”™æ—¶ç­‰å¾…5ç§’å†é‡è¯•
        
        state_manager.consumer_active = False
    
    def mock_data_loop(self):
        """æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå¾ªç¯"""
        state_manager.consumer_active = True
        
        # æ‰©å±•çš„æ¨¡æ‹Ÿç«è½¦æ•°æ®ï¼Œè¦†ç›–æ›´å¤šè·¯çº¿
        mock_trains = [
            {"rid": "MOCK001", "uid": "L12345", "route": [("LONDON", "BRMNGM")], "speed": 0.001},
            {"rid": "MOCK002", "uid": "L67890", "route": [("MNCHSTR", "LONDON")], "speed": 0.0008},
            {"rid": "MOCK003", "uid": "L11111", "route": [("EDINBGH", "LONDON")], "speed": 0.0012},
            {"rid": "MOCK004", "uid": "L22222", "route": [("LONDON", "EDINBGH")], "speed": 0.0009},
            {"rid": "MOCK005", "uid": "L33333", "route": [("BRMNGM", "MNCHSTR")], "speed": 0.0007},
            {"rid": "MOCK006", "uid": "L44444", "route": [("LONDON", "MNCHSTR")], "speed": 0.0011},
            {"rid": "MOCK007", "uid": "L55555", "route": [("EDINBGH", "BRMNGM")], "speed": 0.0006},
            {"rid": "MOCK008", "uid": "L66666", "route": [("MNCHSTR", "EDINBGH")], "speed": 0.0010},
            {"rid": "MOCK009", "uid": "L77777", "route": [("BRMNGM", "LONDON")], "speed": 0.0013},
            {"rid": "MOCK010", "uid": "L88888", "route": [("LONDON", "CRLN")], "speed": 0.0015},
            {"rid": "MOCK011", "uid": "L99999", "route": [("CRLN", "WOLWCHA")], "speed": 0.0008},
            {"rid": "MOCK012", "uid": "L00000", "route": [("WOLWCHA", "LONDON")], "speed": 0.0012},
        ]
        
        # ä¸ºæ¯ä¸ªç«è½¦åˆå§‹åŒ–è¿›åº¦
        for train in mock_trains:
            train["progress"] = 0.0  # åˆå§‹è¿›åº¦
            train["direction"] = 1   # 1ä¸ºæ­£å‘ï¼Œ-1ä¸ºåå‘
        
        while self.running:
            try:
                import random
                
                for train in mock_trains:
                    # ç”Ÿæˆæ¨¡æ‹Ÿä½ç½®æ•°æ®
                    from_tpl, to_tpl = train["route"][0]
                    from_coords = coord_of(from_tpl)
                    to_coords = coord_of(to_tpl)
                    
                    if from_coords and to_coords:
                        # æ›´æ–°ç«è½¦è¿›åº¦ï¼ˆæ¨¡æ‹ŸçœŸå®ç§»åŠ¨ï¼‰
                        speed = train.get("speed", 0.001)
                        direction = train.get("direction", 1)
                        
                        # æ›´æ–°è¿›åº¦
                        train["progress"] += speed * direction
                        
                        # åˆ°è¾¾ç»ˆç‚¹æ—¶åå‘
                        if train["progress"] >= 1.0:
                            train["progress"] = 1.0
                            train["direction"] = -1
                        elif train["progress"] <= 0.0:
                            train["progress"] = 0.0
                            train["direction"] = 1
                        
                        # è®¡ç®—å½“å‰ä½ç½®
                        ratio = train["progress"]
                        lat = from_coords[0] + (to_coords[0] - from_coords[0]) * ratio
                        lon = from_coords[1] + (to_coords[1] - from_coords[1]) * ratio
                        
                        # ç¡®å®šçŠ¶æ€
                        if ratio <= 0.05 or ratio >= 0.95:
                            state = "dwell"  # åœ¨è½¦ç«™åœé 
                        elif train["direction"] == 1:
                            state = "enroute"
                        else:
                            state = "enroute"
                        
                        # éšæœºæ·»åŠ ä¸€äº›åœé çŠ¶æ€
                        if random.random() < 0.1:  # 10%æ¦‚ç‡åœé 
                            state = "stopped"
                        
                        position_data = {
                            "rid": train["rid"],
                            "uid": train["uid"],
                            "ts": datetime.now().isoformat(),
                            "from_tpl": from_tpl if direction == 1 else to_tpl,
                            "to_tpl": to_tpl if direction == 1 else from_tpl,
                            "lat": lat,
                            "lon": lon,
                            "ratio": ratio,
                            "state": state,
                            "platform": random.choice([None, "1", "2", "3", "4", "5"]) if state == "dwell" else None,
                        }
                        
                        state_manager.update_position(train["rid"], position_data)
                        state_manager.message_count += 1
                
                # ä½¿ç”¨è¾ƒçŸ­çš„æ›´æ–°é—´éš”è¿›è¡Œæ¼”ç¤ºï¼ˆ10ç§’ï¼‰
                demo_interval = min(10, config.update_interval)
                time.sleep(demo_interval)
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®æ—¶å‡ºé”™: {e}")
                time.sleep(30)
        
        state_manager.consumer_active = False
    
    def process_message(self, msg):
        """å¤„ç†Kafkaæ¶ˆæ¯"""
        try:
            wrapper = json.loads(msg.value().decode("utf-8"))
            state_manager.last_wrapper = wrapper
            state_manager.message_count += 1
            
            raw = wrapper.get("bytes")
            data = json.loads(raw) if raw else wrapper
            state_manager.last_payload = data

            # ä½¿ç”¨æ¶ˆæ¯æ—¶é—´æˆ³ä½œä¸ºæ—¶é—´åŸºå‡†
            ts_iso = data.get("ts")
            try:
                now = datetime.fromisoformat(ts_iso) if ts_iso else datetime.utcnow().replace(tzinfo=timezone.utc)
            except Exception:
                now = datetime.utcnow().replace(tzinfo=timezone.utc)

            uR = data.get("uR", {})
            TS = uR.get("TS") or {}
            rid = TS.get("rid")
            uid = TS.get("uid")
            ssd = TS.get("ssd") or now.date().isoformat()
            locs: Any = TS.get("Location") or []
            
            # æ ‡å‡†åŒ–Locationä¸ºåˆ—è¡¨
            if isinstance(locs, dict):
                locs = [locs]
            if not rid or not locs:
                return

            res = find_prev_next(locs, ssd, now)
            if not res:
                # å•ç«™æ›´æ–°ï¼šè§†ä¸ºåœé 
                if len(locs) == 1:
                    only = locs[0]
                    tpl = only.get("tpl")
                    coords = coord_of(tpl)
                    if coords:
                        plat = only.get("plat")
                        platform = plat if isinstance(plat, str) else (plat.get("") if isinstance(plat, dict) else None)
                        position_data = {
                            "rid": rid,
                            "uid": uid,
                            "ts": ts_iso or now.isoformat(),
                            "from_tpl": tpl,
                            "to_tpl": tpl,
                            "lat": coords[0],
                            "lon": coords[1],
                            "ratio": 0.0,
                            "state": "dwell",
                            "platform": platform,
                        }
                        state_manager.update_position(rid, position_data)
                    # ä¸å†è®°å½•è­¦å‘Šï¼Œé™é»˜è·³è¿‡æ²¡æœ‰åæ ‡çš„ç«™ç‚¹
                return

            prev_loc, next_loc, t0, t1 = res
            pos = estimate_position(prev_loc, next_loc, t0, t1, now)
            if not pos:
                # å›é€€ï¼šå›ºå®šåˆ°æœ‰åæ ‡çš„ç«¯ç‚¹
                p = coord_of(prev_loc.get("tpl"))
                n = coord_of(next_loc.get("tpl"))
                if n or p:
                    lat, lon = (n or p)
                    pos = {"lat": lat, "lon": lon, "ratio": 0.0, "state": "unknown"}
                else:
                    # é™é»˜è·³è¿‡æ²¡æœ‰åæ ‡æ•°æ®çš„ç«è½¦ï¼Œä¸è®°å½•è­¦å‘Š
                    return

            # å¹³å°ä¿¡æ¯å¤„ç†
            plat = None
            pfield = prev_loc.get("plat")
            if isinstance(pfield, str):
                plat = pfield
            elif isinstance(pfield, dict):
                plat = pfield.get("") or pfield.get("plat")

            position_data = {
                "rid": rid,
                "uid": uid,
                "ts": ts_iso or now.isoformat(),
                "from_tpl": prev_loc.get("tpl"),
                "to_tpl": next_loc.get("tpl"),
                "lat": pos["lat"],
                "lon": pos["lon"],
                "ratio": pos["ratio"],
                "state": pos["state"],
                "platform": plat,
            }
            
            state_manager.update_position(rid, position_data)
            
        except Exception as e:
            state_manager.last_error = str(e)
            state_manager.error_count += 1
            logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

# ===== FastAPI for Google Maps polling ===== #
app = FastAPI(title="Darwin Train Realtime Locator")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== åº”ç”¨å¯åŠ¨å’Œå…³é—­å¤„ç† ===== #
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    logger.info("ğŸš‚ Darwinå®æ—¶ç«è½¦ä½ç½®æœåŠ¡å¯åŠ¨")
    logger.info(f"é…ç½®: æ›´æ–°é—´éš”={config.update_interval}ç§’, æœ€å¤§æ•°æ®å¹´é¾„={config.max_age_hours}å°æ—¶")
    
    # æ¸…ç†å¯åŠ¨æ—¶çš„æ—§æ•°æ®
    try:
        state_manager.cleanup_old_positions()
        logger.info("å¯åŠ¨æ—¶æ•°æ®æ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"å¯åŠ¨æ—¶æ•°æ®æ¸…ç†å¤±è´¥: {e}")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    logger.info("æ­£åœ¨å…³é—­Darwinå®æ—¶ç«è½¦ä½ç½®æœåŠ¡...")
    kafka_manager.stop()
    logger.info("æœåŠ¡å·²å…³é—­")

# åˆ›å»ºå¹¶å¯åŠ¨Kafkaæ¶ˆè´¹è€…ç®¡ç†å™¨
kafka_manager = KafkaConsumerManager()
kafka_manager.start()

# ===== æ ¹ç«¯ç‚¹ ===== #
@app.get("/")
def root():
    """æ ¹ç«¯ç‚¹ï¼Œæä¾›APIä¿¡æ¯"""
    return {
        "service": "Darwinå®æ—¶ç«è½¦ä½ç½®æœåŠ¡",
        "version": "2.0",
        "endpoints": {
            "positions": "/positions - è·å–æ‰€æœ‰ç«è½¦ä½ç½®",
            "position": "/positions/{rid} - è·å–ç‰¹å®šç«è½¦ä½ç½®",
            "config": "/config - è·å–é…ç½®ä¿¡æ¯",
            "stats": "/debug/stats - è·å–ç»Ÿè®¡ä¿¡æ¯",
            "tiplocs": "/tiplocs - è·å–TIPLOCåæ ‡",
            "health": "/health - å¥åº·æ£€æŸ¥"
        },
        "features": [
            "å®æ—¶ä½ç½®ä¼°ç®—",
            "å¯é…ç½®æ›´æ–°é—´éš”",
            "æ•°æ®æŒä¹…åŒ–",
            "è‡ªåŠ¨æ•°æ®æ¸…ç†",
            "æ¨¡æ‹Ÿæ•°æ®æ”¯æŒ"
        ]
    }


class Position(BaseModel):
    rid: str
    uid: Optional[str] = None
    ts: str
    from_tpl: str
    to_tpl: str
    lat: float
    lon: float
    ratio: float
    state: str
    platform: Optional[str] = None


@app.get("/positions")
def get_positions(
    limit: int = Query(default=1000, description="æœ€å¤§è¿”å›æ•°é‡"),
    state: Optional[str] = Query(default=None, description="æŒ‰çŠ¶æ€è¿‡æ»¤ (enroute, dwell, stopped)"),
    max_age_minutes: int = Query(default=1440, description="æœ€å¤§æ•°æ®å¹´é¾„ï¼ˆåˆ†é’Ÿï¼‰")
):
    """è·å–æ‰€æœ‰ç«è½¦ä½ç½®"""
    try:
        positions = state_manager.get_all_positions()
        
        # æŒ‰æ—¶é—´è¿‡æ»¤
        cutoff_time = datetime.now() - timedelta(minutes=max_age_minutes)
        filtered_positions = []
        
        for pos in positions:
            try:
                # å°è¯•è§£ææ—¶é—´æˆ³ï¼Œä¼˜å…ˆä½¿ç”¨updated_atï¼ˆæ›´å¯é ï¼‰
                pos_time_str = pos.get('updated_at') or pos.get('ts', '')
                if not pos_time_str:
                    continue
                
                # å¤„ç†ä¸åŒçš„æ—¶é—´æˆ³æ ¼å¼
                if '+' in pos_time_str and 'T' in pos_time_str:
                    # å¤„ç†å¸¦æ—¶åŒºçš„ISOæ ¼å¼: 2025-09-05T13:33:01.3680409+01:00
                    pos_time = datetime.fromisoformat(pos_time_str.replace('+01:00', '+00:00'))
                else:
                    # å¤„ç†æ ‡å‡†ISOæ ¼å¼: 2025-09-06T00:40:25.841988
                    pos_time = datetime.fromisoformat(pos_time_str)
                
                # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾ä¸ºUTC
                if pos_time.tzinfo is None:
                    pos_time = pos_time.replace(tzinfo=timezone.utc)
                
                # è½¬æ¢ä¸ºå½“å‰æ—¶åŒºè¿›è¡Œæ¯”è¾ƒ
                now_utc = datetime.now(timezone.utc)
                cutoff_utc = now_utc - timedelta(minutes=max_age_minutes)
                
                if pos_time >= cutoff_utc:
                    # æŒ‰çŠ¶æ€è¿‡æ»¤
                    if state is None or pos.get('state') == state:
                        filtered_positions.append(pos)
            except Exception as e:
                # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
                logger.debug(f"æ—¶é—´è§£æå¤±è´¥ {pos.get('rid', 'unknown')}: {e}")
                continue
        
        # æŒ‰æ—¶é—´æ’åºå¹¶é™åˆ¶æ•°é‡
        filtered_positions.sort(key=lambda x: x.get('ts', ''), reverse=True)
        return filtered_positions[:limit]
        
    except Exception as e:
        logger.error(f"è·å–ä½ç½®æ•°æ®æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/positions/{rid}", response_model=Position)
def get_position(rid: str):
    """è·å–ç‰¹å®šç«è½¦çš„ä½ç½®"""
    try:
        # å…ˆä»å†…å­˜ä¸­æŸ¥æ‰¾
        position = state_manager.latest.get(rid)
        if position:
            return position
        
        # å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œä»æ•°æ®åº“æŸ¥æ‰¾
        positions = db_manager.get_all_positions(config.max_age_hours)
        for pos in positions:
            if pos['rid'] == rid:
                return pos
        
        raise HTTPException(status_code=404, detail=f"ç«è½¦ {rid} æœªæ‰¾åˆ°")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ç«è½¦ {rid} ä½ç½®æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ---- Debug endpoints ----
@app.get("/health")
def health():
    return {
        "status": "ok", 
        "bootstrap": config.bootstrap, 
        "topic": config.topic,
        "consumer_active": state_manager.consumer_active,
        "trains_count": len(state_manager.latest)
    }

@app.get("/config")
def get_config():
    """è·å–å½“å‰é…ç½®"""
    return {
        "update_interval": config.update_interval,
        "max_age_hours": config.max_age_hours,
        "db_path": config.db_path,
        "log_level": config.log_level,
        "kafka_configured": bool(config.username and config.password),
    }

@app.post("/config/update-interval/{seconds}")
def update_interval(seconds: int):
    """æ›´æ–°æ•°æ®æ›´æ–°é—´éš”"""
    if seconds < 60:  # æœ€å°1åˆ†é’Ÿ
        raise HTTPException(status_code=400, detail="æ›´æ–°é—´éš”ä¸èƒ½å°‘äº60ç§’")
    if seconds > 3600:  # æœ€å¤§1å°æ—¶
        raise HTTPException(status_code=400, detail="æ›´æ–°é—´éš”ä¸èƒ½è¶…è¿‡3600ç§’")
    
    config.update_interval = seconds
    logger.info(f"æ›´æ–°é—´éš”å·²è®¾ç½®ä¸º {seconds} ç§’")
    return {"message": f"æ›´æ–°é—´éš”å·²è®¾ç½®ä¸º {seconds} ç§’", "update_interval": seconds}

@app.get("/debug/stats")
def debug_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    return {
        "trains_in_memory": len(state_manager.latest),
        "total_messages": state_manager.message_count,
        "error_count": state_manager.error_count,
        "consumer_active": state_manager.consumer_active,
        "last_update": state_manager.last_update.isoformat() if state_manager.last_update else None,
        "has_wrapper": state_manager.last_wrapper is not None,
        "has_payload": state_manager.last_payload is not None,
        "last_error": state_manager.last_error,
        "config": asdict(config),
    }

@app.get("/debug/last-wrapper")
def debug_last_wrapper():
    """è·å–æœ€åçš„KafkaåŒ…è£…å™¨æ•°æ®"""
    return state_manager.last_wrapper or {}

@app.get("/debug/last-payload")
def debug_last_payload():
    """è·å–æœ€åçš„Darwinè½½è·æ•°æ®"""
    return state_manager.last_payload or {}

@app.get("/debug/last-error")
def debug_last_error():
    """è·å–æœ€åçš„é”™è¯¯ä¿¡æ¯"""
    return {"error": state_manager.last_error}

@app.get("/debug/raw-positions")
def debug_raw_positions():
    """è·å–åŸå§‹ä½ç½®æ•°æ®ç”¨äºè°ƒè¯•"""
    try:
        # ç›´æ¥ä»æ•°æ®åº“è·å–æœ€æ–°çš„å‡ æ¡è®°å½•
        positions = db_manager.get_all_positions(config.max_age_hours)
        
        # è¿”å›å‰5æ¡è®°å½•ç”¨äºè°ƒè¯•
        debug_data = {
            "total_in_db": len(positions),
            "memory_count": len(state_manager.latest),
            "sample_positions": positions[:5] if positions else [],
            "sample_memory": list(state_manager.latest.values())[:5] if state_manager.latest else []
        }
        
        return debug_data
        
    except Exception as e:
        logger.error(f"è·å–è°ƒè¯•ä½ç½®æ•°æ®å¤±è´¥: {e}")
        return {"error": str(e)}

@app.post("/debug/cleanup")
def debug_cleanup():
    """æ‰‹åŠ¨æ¸…ç†æ—§æ•°æ®"""
    try:
        state_manager.cleanup_old_positions()
        return {"message": "æ•°æ®æ¸…ç†å®Œæˆ"}
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨æ¸…ç†æ•°æ®æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/tiplocs")
def get_tiplocs():
    """è·å–æ‰€æœ‰TIPLOCåæ ‡"""
    try:
        with sqlite3.connect(config.db_path) as conn:
            cursor = conn.execute("SELECT * FROM tiploc_coords ORDER BY tiploc")
            columns = [desc[0] for desc in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
    except Exception as e:
        logger.error(f"è·å–TIPLOCæ•°æ®æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/tiplocs/{tiploc}")
def add_tiploc(tiploc: str, lat: float, lon: float, name: str = "", source: str = "manual"):
    """æ·»åŠ æˆ–æ›´æ–°TIPLOCåæ ‡"""
    try:
        with sqlite3.connect(config.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO tiploc_coords 
                (tiploc, lat, lon, name, source, updated_at)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (tiploc.upper(), lat, lon, name, source, datetime.now().isoformat()))
        
        logger.info(f"å·²æ·»åŠ /æ›´æ–°TIPLOC: {tiploc} -> ({lat}, {lon})")
        return {"message": f"TIPLOC {tiploc} å·²æ·»åŠ /æ›´æ–°", "tiploc": tiploc, "lat": lat, "lon": lon}
        
    except Exception as e:
        logger.error(f"æ·»åŠ TIPLOCæ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))
